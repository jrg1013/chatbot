\apendice{Especificación de diseño}

\section{Introducción}

En esta sección, se abordan detalladamente las especificaciones de diseño del proyecto, centrándose en la creación de un chatbot basado en \acrlong{llm} y \acrlong{rag}. Las especificaciones de diseño constituyen un componente crucial para el desarrollo eficiente y efectivo del chatbot, definiendo de manera precisa cómo se estructurarán y funcionarán sus distintos elementos. Se exploran aspectos tanto técnicos como funcionales, proporcionando un marco sólido que orientará la implementación del chatbot a lo largo del proyecto.

\section{Diseño de datos}

Se disponen de tres documentos con información relevante acerca de los \acrshort{tfg} del grado de ingeniería informática en la \acrshort{ubu}. Se dispone de la normativa de \acrlong{tfg} en PDF, un documento con preguntas y respuestas tipo \acrshort{faq} en formato DOCX y el histórico de proyectos en formato CSV.

Se han realizado unas pruebas integrando en el chatbot con \acrshort{rag} los datos sin preprocesar y los resultados no han sido buenos. La información se encuentra en distintos formatos \textit{.docx}, \textit{.csv} y \textit{.pdf} y contiene  comentarios, tablas, pies de página y texto en párrafos. Todo ello hace el proceso de realizar \textit{embeddings} no sea efectivo  y no se pueda recuperar despues información relevante durante el \acrshort{rag}.

\subsection{FAQ Online}

Este documento estaba creado para el Chatbot que usaba DialogFlow para la creación de la aplicación~\cite{UBU-Chatbot}. El documento original era un DOCX que contenía tanto texto, como tablas y comentarios. Se puede encontrar en el siguiente enlace: \url{https://github.com/jrg1013/chatbot/blob/main/datasets/ListadoPreguntas-Respuestas%20-%20ONLINE.docx}.

La información en el \acrshort{faq} está segmentada y en el proceso de creación de los \textit{Embeddings}, al no tener una estructura definida los \textit{chunks} no mantenían la estructura semántica. Es cierto que el Chatbot respondía algunas preguntas correctamente al exportar el documento original a TXT de forma automática, pero parte de las preguntas y respuestas se mezclaban al no separarse correctamente.

Se han exportado los datos a formato CSV y se han estructurado mejor. Se puede encontrar el nuevo archivo en el siguiente enlace: \url{https://github.com/jrg1013/chatbot/blob/main/project-app/documents/Preguntas-Respuestas%20-%20ONLINE.csv}.

Al usar el \textit{Data Loader} de LangChain para CSV se ha especificado como fragmentar la información correctamente y cómo interpretar cada columna. Esto ha supuesto una mejora considerable en los resultados del Chatbot y en general la información se recupera adecuadamente de la base de datos vectorial.

\subsection{Histórico de TFGs}

Este documento no es usado en el chatbot anterior y se encuentra en formato CSV. Contiene una lista de los \acrshort{tfg} realizados en la modalidad \textit{online} en los últimos años e información sobre cada uno de esos proyectos como es el nombre de los tutores o el enlace al repositorio. Se puede encontrar en el siguiente enlace: \url{https://github.com/jrg1013/chatbot/blob/main/datasets/TFGHistorico.csv}.

En el histórico de \acrshort{tfg}, se ha mantenido el formato CSV, pero tras varias pruebas, ha sido necesario organizar la información en las celdas de forma adecuada y eliminar algunas columnas para evitar problemas. Se puede encontrar el nuevo archivo en el siguiente enlace: \url{https://github.com/jrg1013/chatbot/blob/main/project-app/documents/TFGHistorico.csv}.

Principalmente los problemas han venido con el \textit{Data Loader} de LangChain para CSVs. Al leer los datos estos deben estar bien estructurados o los \textit{chunks} de información carecerán de sentido y no se recuperará información del \acrshort{rag}. Tras varios intentos se ha logrado realizar recuperación de información reduciendo el tamaño de los \textit{chunks} de los \textit{embeddings} y reduciendo el valor de similitud mínimo.

\subsection{Reglamento para TFG y TFM de la UBU}

El último documento usado para el entrenamiento del chatbot ha sido el PDF que contiene el reglamento para \acrshort{tfg} de la \acrshort{ubu}. Se puede encontrar en el siguiente enlace: \url{https://github.com/jrg1013/chatbot/blob/main/datasets/reglamentp_tfg-tfm_aprob._08-06-2022.pdf}.

El documento del reglamento de la \acrshort{ubu} presenta dificultades a la hora de importar la información en la base de datos vectorial. Principalmente tiene el problema de la estructura de la información con pies de página y encabezados en cada hoja que dificultan la creación de trozos de información coherentes. 

El segundo problema es que estamos combinando distintos tipos de \textit{embeddings}. Uno más estructurado proveniente de CSV y otro con lenguaje natural desde un PDF. No es una situación ideal que se intentará manejar en el proceso de recuperación de la información y la parte generativa a través del \textit{prompt}. Este documento no ha sido tratado y se usa el \textit{Data Loader} PyPDFLoader.

\section{Diseño procedimental}

\subsection{CU-01: Generación de respuestas}

Desde el punto de visto del usuario el proceso que sigue el chatbot comienza con la apertura del página del chat en un navegador. En este momento se la aplicación renderiza la \acrshort{ui} y se queda a la espera que que el usuario realice la primera pregunta.

Hasta este momento no se ha dado ningún paso para generar un \acrshort{llm} o usar una técnica \acrshort{rag}. Este proceso comienza una vez que el usuario ha introducido su primera pregunta. Una vez esa pregunta se hace llegar hasta la lógica de negocio, esta intenta generar una conexión con la \acrshort{api} de HuggingFace. Dependiendo de si la conexión tiene éxito o no, la aplicación devuelve un error o empieza a generar la configuración del \acrshort{llm}. Este paso solo tiene lugar al emitir la primera pregunta de una sesión. A partir de esta primera pregunta, la conexión con la \acrshort{api} permanece abierta hasta finalizar la sesión.

Una vez establecido el \acrshort{llm} se pasa al \acrshort{rag}. Se hace una búsqueda por similitud en la base de datos vectorial para recuperar la información relevante a la pregunta realizada. Una vez recuperada esta información se genera un \textit{prompt} sumando esta información a la pregunta original~\cite{Lewis2020}.

Con el \textit{prompt} y la configuración del \acrshort{llm}, se puede enviar la \textit{query} a HuggingFace. Esta emitirá un error o una respuesta que será transmitida hasta la \acrshort{ui} del chatbot. 

Todo este proceso se puede ver en el diagrama de secuencia en la figura~\ref{fig:diagramaSecuencia}.

\imagen{diagramaSecuencia}{Diagrama de secuencia CU-01: Generación de respuestas.}

\subsection{CU-02: Actualizar datos del bot}

\imagen{diagramaSecuencia2}{Diagrama de secuencia CU-02: Actualizar datos del bot.}

\subsection{CU-03: Validación del chatbot}

\imagen{diagramaSecuencia3}{Diagrama de secuencia CU-03: Validación del chatbot.}

\section{Diseño arquitectónico}

Comparado con versiones anteriores del chatbot, este tiene una arquitectura más compleja, ya que no se utiliza un producto disponible, sino que se utilizan distintos recursos y servicios.

Como se puede ver en la figura~\ref{fig:Architecture}, existen principalmente cuatro bloques en la arquitectura y la validación.

\begin{itemize}
    \item \textbf{Base de datos vectorial:} Para la creación de la base de datos se usará LangChain y FAISS, ambos se han explicado en detalle en las secciones correspondientes de la memoria. La principal ventaja de una base de datos vectorial es que permite realizar búsquedas y recuperación de datos rápida y precisa basada en la distancia o similitud de sus vectores. Esto significa que, en lugar de utilizar métodos tradicionales para consultar bases de datos basadas en coincidencias exactas o criterios predefinidos, se puede utilizar una base de datos vectorial para encontrar los datos más similares o relevantes según su significado semántico o contextual.

    Para realizar la base de datos vectorial basada en los datos de las \acrshort{faq} del \acrlong{tfg}, se crean \textit{embeddings} usando LangChain y separando la información de los CSV en función del atributo que representan. Posteriormente se guarda la base de datos vectorial en memoria y ya estaría lista para ser utilizada por el chatbot.

    Este sección se ha separado en un módulo independiente de Python para no tener que crear una base de datos cada vez que se ejecuta el chatbot si no se han añadido datos nuevos. De esta manera el proceso de ``entrenamiento'' del chatbot y el de ejecución son independientes el uno del otro, lo que mejora el rendimiento y la mantenibilidad del código.

    \item \textbf{HuggingFace \acrshort{api}:} HuggingFace ofrece una \acrshort{api} de canalización (\textit{Pipeline API}) que simplifica el uso de modelos complejos para tareas específicas. Esto hace que sea fácil utilizar modelos de \acrshort{pln} preentrenados para clasificación de texto, traducción, resumen y más. En concreto en este \acrshort{tfg} se ha optado por el \acrshort{llm} de Mistral.

    Para usar la \acrshort{api} es necesario disponer de un \textit{Token} de acceso a HuggingFace. Este Token es gratuito para Mistral, pero no es así para otros modelos. Una vez iniciado el acceso a la \acrshort{api} el resto de la gestión del \acrshort{llm} se realiza a través de LangChain de forma muy sencilla.

    \item \textbf{\acrshort{rag} en LangChain:} Como se ha indicado en la memoria se ha optado por el framework LangChain para la gestión del \acrshort{llm}. LangChain es un \textit{framework} que simplifica el proceso de creación de interfaces de aplicaciones de inteligencia artificial generativa. Los desarrolladores que trabajan en este tipo de interfaces utilizan diversas herramientas para crear aplicaciones avanzadas de \acrshort{pln}; LangChain agiliza este proceso.

    Este módulo es el principal del chatbot y es el que realiza la recuperación de la base de datos vectorial de la información relevante y luego la envía a la \acrshort{api}. Esta gestión se realiza con LangChain y se completa con la configuración adaptada a nuestras necesidades. Tiene una gran importancia no solo los parámetros seleccionados sino también el \textit{prompt} seleccionado.

    \item \textbf{Interfaz gráfica:} Aunque se ha probado con FastAPI para aislar el \textit{frontend} del \textit{backend}. Finalmente se ha optado por usar Streamlit para la creación de la \acrshort{ui}. Esto se debe a la facilidad que esta herramienta nos da para la creación de aplicaciones muy visuales basadas en el \textit{backend} en Python.

    Streamlit funciona con una estructura Cliente-Servidor, siendo Streamlit el que en nuestro caso iniciará el resto de los procesos. Cada vez que se inicie la aplicación, esto acarreará que en la primera ejecución de una pregunta al chatbot, se abra la conexión con la \acrshort{api} que permanecerá abierta hasta que se cierre la aplicación. 

    \item \textbf{Validación:} Como módulo parcialmente separa se tiene el sistema de validación. Este modulo usará el \acrfull{llm} para validar los resultados dados por el chatbot. Es un módulo adicional que utiliza todo lo mencionado anteriormente con excepción del apartado gráfico.
 
\end{itemize}

\imagen{Architecture}{Arquitectura de software del chatbot donde se describen los componentes y sus interfaz.}

