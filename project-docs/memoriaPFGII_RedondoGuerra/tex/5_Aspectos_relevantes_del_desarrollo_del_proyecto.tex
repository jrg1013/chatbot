\capitulo{5}{Aspectos relevantes del desarrollo del proyecto}

En este apartado se mustran los aspectos mas relevantes de este \acrshort{tfg}. Se hace especial hincapié en los decisiones y apartados que mayor influencia han tenido en el proyecto. Por el carácter de investigación del trabajo y por lo temprano del desarrollo de esta tecnología, parte de este apartado está dedicado a la problemática que surge al emplear técnicas y herramientas que en constante cambio.

\section{Selección de un LLM}

Los \acrfull{llm} evolucionan con rapidez y continuamente aparecen nuevos modelos. Esto supone un reto: ¿Cómo seleccionar el \acrshort{llm} más adecuado para este proyecto? En este apartado se analizan las consideraciones prácticas que han guiado el proceso de toma de decisiones.

\subsection{Licencias y uso comercial}
Una consideración crucial a la hora de elegir un \acrshort{llm} es la concesión de licencias. Posiblemente el mas conocido y evolucionado es el \acrshort{gpt} de OpenAI, pero es un modelo que puede tener un coste considerable. En cada \textit{query} se ha de pagar una pequeña cantidad  por token. Para el objeto de este proyecto es mas adecuado el uso de un \acrshort{llm} de \textit{open-source} o por lo menos con una licencia comunitaria para investigación y educación.

Aunque muchos modelos abiertos tienen restricciones de uso comercial, existen modelos disponibles para aplicaciones comerciales. Por ejemplo, la familia de modelos MPT de MosaicML se publica bajo licencias que permiten su uso comercial. Se puede obtener más información sobre las distintas licencias en la \textit{Open Source Initiative} y a traves de la plataforma HugginFace.

\subsection{Factores prácticos para la velocidad de inferencia y la precisión}
Los factores prácticos desempeñan un papel crucial a la hora de determinar la idoneidad de un \acrshort{llm} para el proyecto. Evaluar la velocidad de inferencia (el tiempo que tarda un \acrshort{llm} en procesar y generar resultados) es esencial, sobre todo cuando se trata de grandes cantidades de datos no estructurados. Una inferencia lenta puede dificultar la extracción de información de nuestro chatbot. Optar por modelos optimizados para una inferencia más rápida o capaces de manejar volúmenes de entrada sustanciales puede resultar ventajoso peor también será un modelo mas pesado. Además, si se requiere una gran precisión en el análisis de sentimientos, la selección de un \acrshort{llm} con precisión y análisis de grano fino resulta crucial, y la velocidad de inferencia pasa a ser una consideración secundaria.

\subsection{El impacto de la longitud del contexto y el tamaño del modelo}
Tener en cuenta la longitud del contexto y el tamaño del modelo es crucial a la hora de evaluar los \acrshort{llm}. Mientras que muchos \acrshort{llm} tienen limitaciones en la longitud de entrada, los modelos abiertos más recientes como Salesforce X-Gen admiten longitudes de contexto más largas, lo que permite entradas más completas y resultados deseados. El tamaño del modelo también influye en los requisitos de infraestructura, ya que los modelos más pequeños (menos de siete mil millones de parámetros) son más fáciles de implementar en hardware básico, lo que agiliza la implementación práctica. Por el contrario, algunos \acrshort{llm} ofrecen flexibilidad en el procesamiento de entradas más cortas, pero compensan con parámetros más grandes, atendiendo a casos de uso en los que la precisión dentro de un contexto restringido es primordial. Los \acrshort{llm} con contextos más largos y modelos de mayor tamaño tienden a ser más potentes, pero también tienen mayores exigencias computacionales.

\subsection{Específicos para una tarea o de uso general}
Cuando se trata de \acrfull{llm}, a menudo está la disyuntiva de elegir entre \acrshort{llm} específicos para una tarea o \acrshort{llm} multitarea de propósito general que utilizan \textit{prompts}. Mientras que estos últimos ofrecen versatilidad, los \acrshort{llm} para tareas específicas suelen ser más prácticos y eficientes para caso concretos de uso. Estos modelos especializados se entrenan y ajustan específicamente para una tarea concreta, lo que mejora el rendimiento y la precisión. 

Otro aspecto relacionado es el idioma de entremetimiento del \acrshort{llm}. Los modelos mas extendidos como LLaMa, OpenAI O Mistral, son modelos entrenados principalmente con grandes volúmenes de datos en ingles. Algunos modelos están específicamente entrenados y diseñados para responder en otros idiomas, como Ǎguila\cite{Ǎguila} para español, o multilenguaje como PolyLM\cite{wei2023polylm}.

\subsection{Pruebas y evaluación}
Las pruebas y evaluaciones exhaustivas son cruciales para determinar la fiabilidad de los \acrshort{llm}. Un método eficaz consiste en crear un conjunto de pruebas con ejemplos etiquetados manualmente. Una anotación fiable garantiza mediciones precisas. La comparación de los resultados de los modelos \acrshort{llm} con las referencias etiquetadas ayuda a calcular las métricas de precisión. 

Se hablará mas acerca de este aspecto en una sección posterior, ya que la solución de validación del chatbot dependerá mas del framework de acceso, Langcgain, que del \acrshort{llm} elegido.

\subsection{La revolución de los modelos abiertos}
Recientemente, la adopción de modelos abiertos ha ido en aumento debido a factores como la preocupación por la privacidad de los datos y la rentabilidad. Los modelos abiertos, formados a partir de datos públicos, resuelven los problemas de privacidad asociados a los modelos cerrados. Además, a menudo ofrecen opciones más asequibles. Puede explorar recursos de \acrshort{llm} abiertos en Huggingface y consultar la tabla de clasificación de \acrshort{llm} de \textit{LlamaIndex}\cite{LlamaIndex}.

\subsection{Consideraciones sobre los costes de implementación}
Al seleccionar un \acrshort{llm}, el coste de implementación es también importante, no solo el coste por uso. El tamaño del modelo, los requisitos informáticos y la configuración de la infraestructura influyen en el coste total. Para la escalabilidad, se pueden considerar técnicas de optimización de modelos como la cuantificación(\textit{quantification}), la aceleración de hardware o los servicios cloud para reducir costes. Lograr un equilibrio entre el rendimiento y la asequibilidad de la plataforma es esencial.

Tras realizar algunas pruebas con modelos locales y cuantificación, se optó por usar mejor la \acrshort{api} de HuggingFace. Aunque se tengan algunos retrasos en el establecimiento de la conexión y en momentos puntuales el tiempo de respuesta sea mas lento de lo deseado, se considera que es la mejor opción. La \acrshort{api} permite usar el Chatbot por terceros de forma mas sencilla, sin tener que instalar modelos locales y depender de las características de la \acrshort{cpu} del equipo local.

\subsection{La necesidad de adaptarse al rápido ritmo del cambio}
Casi cada semana se producen cambios en los \acrshort{llm}. Es un momento apasionante pero igualmente supone un reto para desarrollar versiones estables del chatbot. Se seleccionará un \acrshort{llm} que se adapte al caso de uso, y se usarán interfaces de acceso como LangChain que permitan reemplazar el \acrshort{llm} en caso de ser necesario, sin tener que rehacer el chatbot completamente.

Se hablará mas acerca de este aspecto y como ha influido, no solo en la elección del \acrshort{llm} sino también en el resto de aspectos del proyecto.

\subsection{Comparativa de LLMs}

Se han valorado distintos aspectos, y se han probado en mayor o menor medida varios \acrshort{llm}. Los aspectos que se han valorado en mayor profundidad se han recogido en la  tabla \ref{tabla:comparativallm}\cite{Hostinger}\cite{MindsDB}\cite{LlamaIndex}.

\tablaSmall{Comparativa entre distintos \acrlong{llm}}{l c c c c}{comparativallm}
{ \multicolumn{1}{l}{Modelo} & Multilenguaje & API & Open Source & Privacidad \\}{ 
GPT-4 & X & X & &\\
LLaMA 2 & / & / & X &\\
Bard & / & X & &\\
Claude & / & & & /\\
Mistral & / & / & X & X\\
OpenOrca &  & / & X & /\\
} 

\subsection{Modelo elegido: Mistral}

Como ya se ha mencionado anteriormente, Mistral es una Startup Francesa que en solo unos meses ha conseguido una gran repercusión en el mundo de los \acrshort{llm} y del \acrshort{pln}. En comparación con otros modelos como LLaMa 2, Mistral 7B ofrece capacidades similares o mejores pero con menos carga computacional. Mientras que modelos fundacionales como GPT-4 pueden tener un mejor desempeño, Mistral ofrece una \acrshort{api} gratuita a través de HuggingFace. 

El modelo tiene 7B de parámetros y aunque modelos de mas parámetros podrían dar mejores resultados, para la investigación que se desarrolla en este \acrshort{tfg} resulta mas interesante poder realizar las pruebas sin incurrir en costes y tecnología propietaria como la de OpenAI.

Como alternativa a Mistral se ha desarrollado también en la fase de prototipado una segunda versión del Chatbot usando LLaMa 2 de Meta. En general ambos modelos en sus versiones de 7B de parámetros dan resultados similares, pero LLaMa 2 requiere solicitar acceso a la \acrshort{api} para usos en investigación y no se encuentra en la Unión Europea, por lo que no tiene las mismas medidas para la protección de datos.

\section{Fase temprana en la inteligencia artificial generativa}

El inicio de la inteligencia artificial generativa marcó un hito significativo en el campo de la tecnología. Se refiere a la capacidad de las máquinas para generar contenido, especialmente en forma de texto, imágenes y otros tipos de datos. Un momento crucial en este avance fue la introducción de modelos de lenguaje generativos, como \acrfull{gpt}, que son capaces de entender, interpretar y generar texto de manera coherente y contextual.

Este desarrollo ha llevado a avances notables en diversas aplicaciones, como chatbots más inteligentes, asistentes virtuales más avanzados y generación automática de contenido creativo. Desde que OpenAI lanzara ChatGPT el 30 de noviembre de 2022, los avances y mejoras en este campo ha sufrido un avance vertiginoso. 

\imagen{TimelineGAI}{Avances en el campo de la Inteligencia Artificial Generativa en los últimos meses.}{1}

Uno de los factores clave en este rápido desarrollo es el enfoque de preentrenamiento de estos modelos, lo que significa que son entrenados en grandes cantidades de datos antes de ser afinados para tareas específicas. Esto les permite capturar patrones complejos y contextos, lo que resulta en un rendimiento más sofisticado. 

Sin embargo, este avance también ha planteado desafíos éticos y preocupaciones sobre el uso responsable de la inteligencia artificial generativa. La capacidad de crear contenido realista y convincente ha llevado a debates sobre la desinformación, la manipulación de información y la necesidad de salvaguardias para garantizar un uso ético y beneficioso de estas tecnologías.

En resumen, el inicio de la inteligencia artificial generativa es una fase emocionante con avances notables casi a diario, pero también plantea importantes consideraciones éticas y aspectos que se deben consolidar para garantizar un desarrollo tecnológico viable.

\subsection{Fase de investigación y desarrollo vs fase de explotación}

La \acrshort{ia} ha experimentado avances significativos en investigación y desarrollo, con la creación de \acrshort{llm}, redes neuronales profundas y enfoques innovadores para tareas específicas. Sin embargo, la aplicación masiva y generalizada de la \acrshort{ia} a productos en fase de explotación sigue siendo un desafío en muchos casos.

Algunas razones para esta brecha entre la investigación y la implementación amplia incluyen:

\begin{itemize}

\item \textbf{Multitples vias de desarrollo:} A pesar de su corta historia, existen multitud de herramientas, técnicas y estrategias relacionadas con los \acrshort{llm}. En esta fase temprana no se ha consolidado una dirección como paradigma ha seguir por lo que existen muchos caminos de investigación que meses después se abandonan para proseguir por otros mas prometedores.

\item \textbf{Complejidad de Tareas del Mundo Real:} Muchas tareas del mundo real son complejas y requieren un entendimiento profundo del contexto. Aunque los modelos de \acrshort{ia} han progresado, aún pueden enfrentar dificultades para manejar situaciones impredecibles o interpretar información de manera sutil.

\item \textbf{Interpretabilidad y Transparencia:} Los modelos de \acrshort{ia}, especialmente los de aprendizaje profundo, a menudo son cajas negras difíciles de interpretar. En entornos críticos, como la atención médica o la toma de decisiones legales, la interpretabilidad es esencial, y la falta de comprensión completa puede limitar la adopción.

\item \textbf{Ética y Sesgo:} Las preocupaciones éticas relacionadas con el sesgo en los datos y la toma de decisiones algorítmica han generado discusiones importantes. La necesidad de abordar el sesgo y garantizar decisiones justas y equitativas sigue siendo un desafío.

\item \textbf{Regulaciones y Normativas:} La implementación de la \acrshort{ia} a menudo se ve afectada por regulaciones y normativas en evolución. Como la aprobada recientemente en la Unión Europea. Las preocupaciones sobre la privacidad, la seguridad y el impacto social han llevado a la introducción de leyes y estándares que afectan la aplicación generalizada.

\end{itemize}

A pesar de estos desafíos, es importante destacar que la \acrshort{ia} se está utilizando en diversos sectores, desde asistentes virtuales hasta diagnóstico médico asistido por máquina. A medida que la investigación continúa y se abordan los desafíos actuales, es probable que veamos una mayor aplicación de la \acrshort{ia} en productos y servicios en el futuro.

\subsection{Langchain como \textit{framework} de gestión en un momento de cambio constante}

Por lo anteriormente expuesto, se ha optado por usar Langchain como capa de intermedia para el acceso y gestión de los \acrshort{llm}. Existen ventajas he inconvenientes en su uso y no es seguro de que este \textit{framework} sea la estrategia que se imponga al resto de las posibles vías. A continuación se enumeran algunos de los factores que han determinado esta decisión y también algunos de los inconvenientes que ha traído consigo.

Langchain permite, al menos parcialmente, modificar secciones de la aplicación sin tener que modificar completamente la arquitectura del software. Esto es especialmente interesante en un momento en el que se lanzan nuevos \acrshort{llm} y herramientas casi semanalmente. Como se ha indicado anteriormente, la tecnología está actualmente en un momento de cambio constante y de rápido desarrollo, es una fase interesantisima pero también compleja para el desarrollador. 

El uso de esta capa intermedia permite abstraer parte de la implementación, y que cambios de estrategia supongan solo un cambio en una linea de código. Esto funciona bien parcialmente pero no es siempre posible. Por ejemplo la selección del \acrshort{llm} conlleva mas que un simple cambio de argumentos en muchos casos, y no todos los \acrshort{llm} soportan las mismas características o el mismo \textit{prompt}.

Cabe destacar que Langchain se lanzó en Octubre de 2022, por lo que es un \textit{framework} en constante cambio. Muchas funciones se renuevan y son reemplazadas por otras estrategias, haciendo el mantenimiento de código una tarea compleja. Durante la fase de desarrollo, partes del código han tenido que ser reescritas ya que accesos o funciones recomendadas un mes antes, ya no estaban disponibles.

Un aspecto negativo de la elección de esta capa intermedia es la limitación en si misma que este acceso supone. No se tiene control sobre la implementación de las funciones y esto hace que no se pueda optimizar la aplicación fácilmente. A mayores, Langchain está centrada en el uso de la \acrshort{api} de OpenAI, por lo que no todos los \acrshort{llm} reciben el mismo soporte. En el caso de este proyecto usando Mistral 7B, esto supone que parte de las funciones u opciones no esten soportadas.

\section{Preprocesamiento de datos}

El preprocesamiento de datos es una parte fundamental del desarrollo de \acrlong{llm} y \acrlong{rag}. Aunque los detalles específicos del preprocesamiento pueden variar según la tarea y la arquitectura del modelo, algunos pasos comunes incluyen:

\begin{itemize}

\item \textbf{Tokenización:} Los modelos de lenguaje trabajan con unidades más pequeñas llamadas tokens. Tokenizar un texto implica dividirlo en estas unidades, que podrían ser palabras, subpalabras o incluso caracteres.

\item \textbf{Normalización:} Esto implica convertir el texto a un formato estándar, como convertir todas las letras a minúsculas. Esto ayuda a que el modelo no trate las mismas palabras en diferentes formas como entidades separadas.
 
\item \textbf{Eliminación de \textit{Stopwords}:} Para algunos modelos, puede ser beneficioso eliminar palabras comunes que no aportan mucha información (como "y", "o", "el", etc.) para reducir el ruido en los datos.

\item \textbf{Lidiar con Datos No Estructurados:} Si los datos contienen elementos no textuales, como imágenes o tablas, se debe tener un proceso para manejarlos o convertirlos en un formato que el modelo pueda entender.

\item \textbf{Segmentación de Texto:} Para tareas específicas, como la recuperación de respuesta, puede ser útil dividir el texto en segmentos más pequeños para facilitar la búsqueda y la recuperación de información relevante.

\item \textbf{Manejo de Datos Desbalanceados:} Si los datos están desbalanceados (por ejemplo, se tienen muchas más instancias de una clase que de otra), es posible que se desean aplicar técnicas para abordar este desequilibrio.

\end{itemize}

El preprocesamiento puede variar según la tarea y el modelo específico que se está utilizando. Algunos modelos, como \acrfull{gpt}, han demostrado ser bastante robustos y pueden manejar datos en bruto con un preprocesamiento mínimo, mientras que otros modelos pueden requerir una preparación más cuidadosa de los datos. 

Además, para \acrshort{rag}, también hay un enfoque importante en la creación de conjuntos de datos que vinculen preguntas con respuestas relevantes para el entrenamiento efectivo del modelo. 

Los datos que se disponen del \acrshort{faq} para \acrshort{tfg}, la información está en una estructura poco ventajosa para el Chatbot basado en \acrshort{llm}. Se disponen de distintas fuentes de datos que se han de incorporar al \acrshort{rag}.

\subsection{\textit{Document Loaders}}

Los \textit{document loaders} en el contexto de \acrlong{llm} como LLaMa.cpp o Langchain se refieren a componentes o módulos diseñados para cargar documentos o datos en la memoria del modelo. Estos documentos actúan como contexto o información de referencia que el modelo puede utilizar durante el proceso de inferencia para comprender y responder de manera más precisa a las consultas o preguntas que se le presentan. Basicamente es la función que se describe en el método \acrshort{rag}.

En términos generales, la carga de documentos es esencial para proporcionar contexto y conocimiento al modelo, mejorando así su capacidad para generar respuestas significativas. El proceso de carga de documentos implica tomar información desde diversas fuentes, como bases de datos, páginas web, archivos de texto, etc., y convertirla en un formato que el modelo pueda entender y utilizar.

\imagen{DocumentLoaders}{Matriz de representación de los multiples \textit{Document Loaders} disponibles en LangChain.}{1}

En resumen, los \textit{document loaders} son parte fundamental del proceso de preparación de datos para \acrlong{llm}, asegurando que tengan acceso a la información relevante que les permita realizar tareas específicas de manera efectiva.

\subsection{Datos disponibles}

Se han realizado unas pruebas con los datos sin preprocesar y los resultados no han sido buenos. La información se encuentra en formato .docx y contiene tanto comentarios, como tablas como texto en párrafos. Está formato de información estaba creado para el Chatbot que usaba DialogFlow para la creación de la aplicación. 

Esta información es segmentada en el proceso de creación de los \textit{Embeddings} y sin una estructura definida los segmentos no mantenían la estructura semántica. Es cierto que el Chatbot respondía algunas preguntas correctamente al exportar los datos a .txt de forma automática, pero parte de las preguntas y respuestas se mezclaban al no separarse correctamente.

Se han exportado los datos a formato .csv y al usar el \textit{Data Loader} de Langchain se ha especificado como fragmentar la información correctamente y como interpretar cada columna. Esto ha supuesto un salto considerable los resultados del Chatbot y en general la información se recupera adecuadamente de la base de datos vectorial.

Para usar técnicas \acrshort{rag} y en general \acrshort{pln}, se deben usar datos mas similares al lenguaje natural o con una estructura definida. El \acrshort{llm} funciona muy bien en gestionar el lenguaje pero no puede gestionar datos desestructurados, tablas o imágenes.

\section{Validación y pruebas en el procesamiento del lenguaje natural}

La validación de \acrshort{llm} y \acrshort{rag} sigue principios generales de evaluación de modelos de aprendizaje automático. Algunas estrategias comunes son:

\begin{itemize}

\item \textbf{Perplejidad:} La perplejidad es una medida común para evaluar modelos de lenguaje. Cuanto menor sea la perplejidad en un conjunto de datos, mejor es el modelo en la tarea de predecir la secuencia de palabras.

\item \textbf{Evaluación Humana:} Se pueden realizar evaluaciones humanas donde se pide a los evaluadores que califiquen la calidad de las generaciones del modelo en términos de fluidez, coherencia y relevancia.

\item \textbf{\textit{Benchmarks} Estándar:} Utilizar conjuntos de datos de referencia o \textit{benchmarks} estándar puede proporcionar una comparación objetiva con otros modelos.

\item \textbf{Ranking de Respuestas:} Dado que \acrshort{rag} está diseñado para recuperar respuestas de un conjunto de documentos, la evaluación a menudo implica comparar la respuesta generada con respuestas de referencia y clasificarlas según su relevancia.

\item \textbf{BLEU y Otras Métricas de Evaluación de Texto:} Métricas como BLEU se utilizan a menudo para evaluar la similitud entre la respuesta generada y las respuestas de referencia.

\item \textbf{Conjuntos de Datos de Preguntas y Respuestas:} Se pueden crear conjuntos de datos específicos para \acrshort{rag}, donde se proporcionan preguntas y se espera que el modelo recupere respuestas relevantes de documentos externos.

\end{itemize}

Es importante recordar que no hay una métrica única que capture completamente la calidad de un modelo de lenguaje o de respuesta generativa. La combinación de varias métricas y evaluaciones humanas a menudo brinda una visión más completa del rendimiento del modelo. Además, la elección de la estrategia de evaluación puede depender de la tarea específica y de los objetivos del modelo.

De las métricas nombradas anteriormente se ha optado por hacer una mezcla de Evaluación Humana, Conjunto de Datos de Pregunta/Respuesta y \textit{Benchmark}. 

En una primera etapa se ha realizado una validación genérica basada en la evaluación humana. Es relativamente fácil descartar algunas configuraciones que dan respuestas alejadas de lo que se busca.

Un vez que se tiene una estrategia general, se ha realizado un proceso de \textit{Benchmarking} usando una lista de preguntas y respuestas y comparando los resultado con las respuestas previstas. Esto permite realizar un ranking de que configuración da mejores resultados en el \acrshort{rag}. Para ello se han usado 22 preguntas del set de preguntas del que se dispone y se ha generado para cada variación un reporte.

\imagen{Validacion1}{Ejemplo de reporte de testeo de una posible configuración del RAG.}{1}

\subsection{Usar un LLM para validar un LLM}

Un interesante aspecto que se plantea al validar respuestas del chatbot es determinar que es una respuesta correcta. Los \acrshort{llm} son por naturaleza no deterministas y en el lenguaje natural a diferencia de en problemas matematicos, dos respuestas pueden ser distintas y a la vez correctas. 

Para ello se utiliza una interesante estrategia que consiste en usar un \acrshort{llm} para valorar si la respuesta generada por el Chatbot (que ha sido generada por un \acrshort{llm}) contiene la misma información que la respuesta esperada.

Explicado de una forma simplificada, es una llamada a un modelo de generación que incluye un \textit{Prompt} del tipo:

\begin{verbatim}
Prompt: Tienes que valorar si dos respuestas de dadas 
son equivalentes. La información en {respuesta generada} 
es equivalente a la que contiene {respuesta esperada}.
\end{verbatim}

La respuesta de esta consulta será una boleana que nos dirá si es correcto o incorrecto. En teoría esto se puede aplicar usando Langchain pero lamentablemente no está exento de fallos. Esta validación automática es rápida pero tiene un tasa de fallo significativa. Vale como indicación general de lo bueno o malo que es una solución pero se debe comprobar de forma manual.

\imagen{Validacion2}{Ejemplo de la validación de Preguntas y Respuestas del chatbot y su respuesta generada.}{1}